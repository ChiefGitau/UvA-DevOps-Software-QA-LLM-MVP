"""Repair API endpoints (QALLM-12 / US-08, QALLM-12b provider registry)."""

from __future__ import annotations

from typing import Any

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field

from app.services.repair_service import list_providers, run_repair
from app.services.session_service import SessionService

router = APIRouter(prefix="/api", tags=["repair"])


class RepairRequest(BaseModel):
    """Request body for LLM repair."""

    finding_ids: list[str] | None = Field(
        None,
        description="Specific finding IDs to repair. If omitted, repairs "
        "top findings sorted by severity (up to MAX_REPAIR_ISSUES).",
    )
    max_issues: int | None = Field(
        None,
        description="Override the maximum number of findings to repair.",
        ge=1,
        le=50,
    )
    provider: str | None = Field(
        None,
        description="LLM model to use (e.g. 'gpt-4o-mini', 'gpt-5-mini', "
        "'claude-3-5-haiku-20241022', 'ollama/llama3.1:8b'). "
        "If omitted, auto-routes: HIGH/CRITICAL → strong model, MEDIUM/LOW → fast model.",
    )


@router.get(
    "/llm/providers",
    summary="List LLM providers",
    response_description="Available, configured, and default LLM providers",
)
def get_providers() -> dict[str, Any]:
    """Return which LLM providers are registered and which have API keys configured."""
    return list_providers()


@router.post(
    "/repair/{session_id}",
    summary="Repair findings via LLM",
    response_description="Patches generated by the selected LLM with token usage stats",
)
def repair(session_id: str, req: RepairRequest | None = None) -> dict[str, Any]:
    """Send findings to the selected LLM provider for targeted code repair.

    For each finding, the system extracts the surrounding function/class
    context, builds a focused prompt, and asks the LLM to return only
    the corrected code. A unified diff is generated and patches are
    applied to the session workspace.

    **Providers:** Use `GET /api/llm/providers` to see available options.
    Pass ``provider`` in the request body, or set ``LLM_PROVIDER`` env var.
    """
    if not SessionService.session_exists(session_id):
        raise HTTPException(status_code=404, detail="Session not found")

    reports = SessionService.reports_dir(session_id)
    if not (reports / "findings_unified.json").exists():
        raise HTTPException(
            status_code=400,
            detail="No analysis run yet. Run POST /api/analyse first.",
        )

    body = req or RepairRequest()

    try:
        result = run_repair(
            session_id=session_id,
            finding_ids=body.finding_ids,
            max_issues=body.max_issues,
            provider=body.provider,
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

    return {"session_id": session_id, **result}


@router.get(
    "/repair/{session_id}/report",
    summary="Get repair report",
    response_description="Persisted repair patches and token usage",
)
def get_repair_report(session_id: str) -> dict[str, Any]:
    """Retrieve the persisted repair report for a session."""
    if not SessionService.session_exists(session_id):
        raise HTTPException(status_code=404, detail="Session not found")

    import json

    p = SessionService.reports_dir(session_id) / "repair_report.json"
    if not p.exists():
        raise HTTPException(status_code=404, detail="No repair run yet")

    return json.loads(p.read_text(encoding="utf-8"))
