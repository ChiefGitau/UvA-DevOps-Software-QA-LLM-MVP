# === P4 Quality Repair Tool – Environment Variables ===
# Copy to .env and fill in real values:  cp .env.example .env

# Data directory for session storage
DATA_DIR=data

# ── LLM Provider Selection ──────────────────────────────────────
# Which provider to use by default: "openai" or "anthropic"
# Can also be overridden per-request via the API or UI dropdown
LLM_PROVIDER=openai
#LLM_PROVIDER=ollama

# ── OpenAI ──────────────────────────────────────────────────────
#OPENAI_API_KEY=
#OPENAI_MODEL=gpt-5-mini
OPENAI_MODEL=gpt-4o-mini

# ── Anthropic ───────────────────────────────────────────────────
#ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-5-haiku-20241022


# Point your OllamaProvider at the Ollama container
OLLAMA_BASE_URL=http://ollama:11434
# Pick a default dev model (fast-ish, decent quality)
#OLLAMA_MODEL=llama3.1:8b
#OLLAMA_MODEL=qwen2.5:7b
OLLAMA_MODEL=qwen3-vl:8b

# ── LLM Shared Settings ────────────────────────────────────────
TOKEN_BUDGET=20000
MAX_REPAIR_ISSUES=10

# Storage backend (local only for PoC)
STORAGE_BACKEND=local

# Log level
LOG_LEVEL=INFO
